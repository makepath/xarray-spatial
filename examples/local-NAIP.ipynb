{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0de53239a7a531c7e7cf1b9e89e89cc6be83ff2612d319bd61005581dea8c85e2",
   "display_name": "Python 3.8.10 64-bit ('local': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Case Study: Using 'Local' functions to analyze urban development and the frequency of landcover change in South Jordan Utah.\n",
    "\n",
    "**Modified from: https://planetarycomputer-staging.microsoft.com/dataset/naip#Example-Notebook**\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Accessing NAIP data with the Planetary Computer STAC API\n",
    "\n",
    "### Environment setup\n",
    "\n",
    "This notebook works with or without an API key, but you will be given more permissive access to the data with an API key.\n",
    "The [Planetary Computer Hub](https://planetarycomputer.microsoft.com/compute) is pre-configured to use your API key."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from pystac_client import Client\n",
    "import planetary_computer as pc\n",
    "\n",
    "# Set the environment variable PC_SDK_SUBSCRIPTION_KEY, or set it here.\n",
    "# The Hub sets PC_SDK_SUBSCRIPTION_KEY automatically.\n",
    "# pc.settings.set_subscription_key(<YOUR API Key>)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Choose our region and times of interest\n",
    "\n",
    "This area is in the Simplot Family farm, one of the largest farms in the US, located outside of Boise Idaho .  Let's see whether we can see some development in this area in the time spanned by our NAIP collection."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = {\n",
    "    \"type\": \"Polygon\",\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [-116.05,43.03],\n",
    "            [-115.97,43.03],\n",
    "            [-115.97,43.07],\n",
    "            [-116.05,43.07],\n",
    "            [-116.05,43.03]            \n",
    "        ]\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "source": [
    "### Search the collection and choose scenes to render\n",
    "\n",
    "Use [pystac-client](https://github.com/stac-utils/pystac-client) to search for data from the [NAIP](http://aka.ms/ai4edata-naip) collection.  This collection includes data from 2010 to 2019, so we'll search for one image near the beginning of that range, one near the middle, and one near the end."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = '2010-01-01/2013-01-01'\n",
    "range2 = '2013-01-01/2017-01-01'\n",
    "range3 = '2018-01-01/2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\")\n",
    "\n",
    "search1 = catalog.search(\n",
    "    collections=['naip'], \n",
    "    intersects=area_of_interest,\n",
    "    datetime = range1\n",
    ")\n",
    "\n",
    "search2 = catalog.search(\n",
    "    collections=['naip'], \n",
    "    intersects=area_of_interest,\n",
    "    datetime = range2\n",
    ")\n",
    "\n",
    "search3 = catalog.search(\n",
    "    collections=['naip'], \n",
    "    intersects=area_of_interest,\n",
    "    datetime = range3\n",
    ")\n",
    "\n",
    "print(f\"{search1.matched()} Items found in the range 1\")\n",
    "print(f\"{search2.matched()} Items found in the range 2\")\n",
    "print(f\"{search3.matched()} Items found in the range 3\")"
   ]
  },
  {
   "source": [
    "As seen above, there are multiple items that intersect our area of interest for each year. The following code will choose the item that has the most overlap:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import shape\n",
    "\n",
    "area_shape = shape(area_of_interest)\n",
    "target_area = area_shape.area\n",
    "\n",
    "def area_of_overlap(item):\n",
    "    overlap_area = shape(item.geometry).intersection(shape(area_of_interest)).area    \n",
    "    return overlap_area / target_area\n",
    "\n",
    "item1 = sorted(search1.items(), key=area_of_overlap, reverse=True)[0]\n",
    "item2 = sorted(search2.items(), key=area_of_overlap, reverse=True)[0]\n",
    "item3 = sorted(search3.items(), key=area_of_overlap, reverse=True)[0]"
   ]
  },
  {
   "source": [
    "### Render images\n",
    "\n",
    "Each Item has an `href` field containing a URL to the underlying image. For NAIP, these URLs are publicly-accessible, but for some data sets, these URLs may point to private containers, so we demonstrate the use of the [planetary-computer](https://github.com/microsoft/planetary-computer-sdk-for-python) package's `pc.sign` method, which adds a [Shared Access Signature](https://docs.microsoft.com/en-us/azure/storage/common/storage-sas-overview) to the URL, after which it can be used by any tooling that expects a standard URL."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio import windows\n",
    "from rasterio import features\n",
    "from rasterio import warp\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "red_band = 1\n",
    "green_band = 2\n",
    "blue_band = 3\n",
    "nir_band = 4\n",
    "\n",
    "def create_image(item):\n",
    "    print(item.datetime)\n",
    "    href = pc.sign(item.assets['image'].href)\n",
    "    with rasterio.open(href) as ds:    \n",
    "        aoi_bounds = features.bounds(area_of_interest)\n",
    "        warped_aoi_bounds = warp.transform_bounds('epsg:4326', ds.crs, *aoi_bounds)\n",
    "        aoi_window = windows.from_bounds(transform=ds.transform, *warped_aoi_bounds)\n",
    "        band_data = ds.read(indexes=[nir_band, red_band], window=aoi_window)\n",
    "\n",
    "    img = Image.fromarray(np.transpose(band_data, axes=[1, 2, 0]))\n",
    "    w = img.size[0]; h = img.size[1]; aspect = w/h\n",
    "\n",
    "\n",
    "    # Downscale a bit for plotting\n",
    "    target_w = 800; target_h = (int)(target_w/aspect)\n",
    "\n",
    "    return img.resize((target_w,target_h),Image.BILINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "img1 = create_image(item1)\n",
    "img2 = create_image(item2)\n",
    "img3 = create_image(item3)"
   ]
  },
  {
   "source": [
    "## Using xarray-spatial to gather statistical information\n",
    "\n",
    "First we will conver the images to `xarray.DataArray` format and then merge them together for easier viewing with `xarray.merge()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datashader.transfer_functions import shade, stack, Images\n",
    "from datashader.colors import Elevation, Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert to DataArrays of the same size\n",
    "agg1 = xr.DataArray(data = img1, name = '2011-07-01', dims = ['x', 'y','band'])[:700, :800, :]\n",
    "agg2 = xr.DataArray(data = img2, name = '2013-08-18', dims = ['x', 'y','band'])[:700, :800, :]\n",
    "agg3 = xr.DataArray(data = img3, name = '2019-07-14', dims = ['x', 'y','band'])[:700, :800, :]\n",
    "\n",
    "# Merge Arrays into single dataset\n",
    "ds = xr.merge([agg1, agg2, agg3])\n",
    "\n",
    "# Near-Infrared Band\n",
    "Images(shade(ds['2011-07-01'][:,:,1]),\n",
    "       shade(ds['2013-08-18'][:,:,1]),\n",
    "       shade(ds['2019-07-14'][:,:,1]))\n",
    "\n",
    "# Red Band\n",
    "Images(shade(ds['2011-07-01'][:,:,0]),\n",
    "       shade(ds['2013-08-18'][:,:,0]),\n",
    "       shade(ds['2019-07-14'][:,:,0]))"
   ]
  },
  {
   "source": [
    "### Create NDVI Images\n",
    "The Normalized Difference Vegetation Index (NDVI) is an indicator used to detect live green vegetation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from xrspatial.multispectral import ndvi\n",
    "\n",
    "# Create arrays using the NIR band (0) and the red band (1)\n",
    "ndvi_2011 = ndvi(nir_agg = ds['2011-07-01'][:, :, 1], red_agg = ds['2011-07-01'][:, :, 0], name = '2011-07-01')\n",
    "ndvi_2013 = ndvi(nir_agg = ds['2013-08-18'][:, :, 1], red_agg = ds['2013-08-18'][:, :, 0], name = '2013-08-18')\n",
    "ndvi_2019 = ndvi(nir_agg = ds['2019-07-14'][:, :, 1], red_agg = ds['2019-07-14'][:, :, 0], name = '2019-07-14')\n",
    "\n",
    "# Merge Arrays into single dataset\n",
    "ds_ndvi = xr.merge([ndvi_2011, ndvi_2013, ndvi_2019])\n",
    "\n",
    "Images(shade(ndvi_2011, cmap = Hot),\n",
    "       shade(ndvi_2013, cmap = Hot),\n",
    "       shade(ndvi_2019, cmap = Hot))\n"
   ]
  },
  {
   "source": [
    "Here we see that there appears to be more vegetation in July and that July of 2019 appeared to have a better growing season than 2011. The dinsity and shape of the NDVI values indicate that we are likely looking at farmland."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Mean & Median\n",
    "Let's find the average and median value of each cell over each time period. These methods are useful for determining the 'true' value of a particular cell, the closer the average/median value is to the value we are looking for, the more likely we are to see that value over time periods outside of our study. While the functions are similar, median will remove outliers which in some cases will prove usefull when large amounts of wild vegetation are present."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "mean = ds_ndvi.to_array(dim = 'new').mean('new').rename('mean')\n",
    "median = ds_ndvi.to_array(dim = 'new').median('new').rename('median')\n",
    "\n",
    "Images(shade(mean, cmap = Hot),\n",
    "       shade(median, cmap = Hot))"
   ]
  },
  {
   "source": [
    "## Majority & Minority\n",
    "Let's find the value that occurs most often on a cell-by-cell basis over each time period. Different crops are likely to produce different NDVI values, determining the most common values can help us distinguish crops. Crops are also more likely to be highly to be clustered, resulting in more of that value within the image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def maximum(array1, array2, array3):\n",
    "    a = np.fmax(array1.data, array2.data)\n",
    "    b = np.fmax(a, array3.data)\n",
    "    out = xr.DataArray(b, name = 'maximum')\n",
    "    return out\n",
    "\n",
    "def minimum(array1, array2, array3):\n",
    "    a = np.fmin(array1.data, array2.data)\n",
    "    b = np.fmin(a, array3.data)\n",
    "    out = xr.DataArray(b, name = 'minimum')\n",
    "    return out\n",
    "\n",
    "min_agg = minimum(ndvi_2011, ndvi_2013, ndvi_2019)\n",
    "max_agg = maximum(ndvi_2011, ndvi_2013, ndvi_2019)\n",
    "\n",
    "Images(shade(min_agg, cmap = Hot),\n",
    "       shade(max_agg, cmap = Hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First lets stack the data using `xarray.concat()`\n",
    "# concat = xr.concat([ds_ndvi[i] for i in ds_ndvi], 'year')\n",
    "# concat = concat.rename('2011-2019')\n",
    "# \n",
    "# # Then iterate through the year axis (0) and look for unique values using `numpy.unique()`.\n",
    "# axis = 0\n",
    "# u, indices = np.unique(concat.data, return_inverse=True)\n",
    "# \n",
    "# # Then create an array showing the most common value on a cell-by-cell basis.\n",
    "# majority = u[np.argmax(np.apply_along_axis(np.bincount, axis, indices.reshape(concat_data.shape), None, np.max(indices) + 1), axis = axis)]\n",
    "# majority = xr.DataArray(majority)\n",
    "# \n",
    "# # First lets stack the data using `xarray.concat()`\n",
    "# concat = xr.concat([ds_ndvi[i] for i in ds_ndvi], 'year')\n",
    "# concat = concat.rename('2011-2019')\n",
    "# \n",
    "# # Then iterate through the year axis (0) and look for unique values using `numpy.unique()`.\n",
    "# axis = 0\n",
    "# u, indices = np.unique(concat.data, return_inverse=True)\n",
    "# \n",
    "# # Then create an array showing the least common value on a cell-by-cell basis.\n",
    "# minority = u[np.argmin(np.apply_along_axis(np.bincount, axis, indices.reshape(concat_data.shape), None, np.min(indices) + 1), axis = axis)]\n",
    "# minority = xr.DataArray(minority)"
   ]
  },
  {
   "source": [
    "## Maximum, Minimum and Range\n",
    "Let's find the largest and smallest value of each cell over each time period, as well as the difference between them. These functions could be useful in distinguishing productive and barren land."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "maximum = ds_ndvi.to_array(dim = 'new').max('new').rename('maximum')\n",
    "minimum = ds_ndvi.to_array(dim = 'new').min('new').rename('minimum')\n",
    "range_agg = maximum - minimum\n",
    "range_agg = range_agg.rename('range')\n",
    "\n",
    "Images(shade(maximum, cmap= Hot),\n",
    "      shade(minimum, cmap = Hot),\n",
    "      shade(range_agg, cmap = Hot))"
   ]
  },
  {
   "source": [
    "## Standard Deviation & Sum\n",
    "Let's find the standard deviation and sum of each cell over each band and time period."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "standard_deviation = ds_ndvi.to_array(dim = 'new').std('new').rename('standard deviation')\n",
    "sum_agg = ds_ndvi.to_array(dim = 'new').sum('new').rename('sum')\n",
    "\n",
    "Images(shade(standard_deviation, cmap = Hot),\n",
    "       shade(sum_agg, cmap = Hot))"
   ]
  },
  {
   "source": [
    "## Variety\n",
    "Let's find all of the unique values across each time period."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's concatenate the ndvi arrays \n",
    "concat_ndvi = xr.concat([ds_ndvi[i] for i in ds_ndvi], 'year')\n",
    "concat_ndvi = concat_ndvi.rename('2011-2019')\n",
    "\n",
    "# Then find all unique values and count them\n",
    "(unique, counts) = np.unique(concat_ndvi.data, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "\n",
    "np.sort(frequencies)"
   ]
  },
  {
   "source": [
    "## Combine\n",
    "Let's combine the rasters by band and look for unique combinations. If our hypothesis is correct, these crops should be producing the same NDVI value and we should see some recurring combinations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def combine_arrays(array1, array2, array3):\n",
    "    unique_combos = {} \n",
    "    unique_values = {}\n",
    "    all_combos = []\n",
    "    all_values = []\n",
    "    value = 1\n",
    "\n",
    "    # Iterate through each array simultaneously\n",
    "    for a, b, c in np.nditer([array1.data, array2.data, array3.data]):\n",
    "        combo = (a.item(), b.item(), c.item())\n",
    "        if np.isnan(combo).any() == True:   # skip nan\n",
    "            all_values.append(np.nan)\n",
    "            all_combos.append('NAN')\n",
    "            continue\n",
    "        if combo in unique_combos.keys():   # apply 0 combos already found\n",
    "            all_combos.append(combo)\n",
    "            all_values.append(0)\n",
    "        else:                               # apply new value to unique combos\n",
    "            unique_combos[combo] = value\n",
    "            unique_values[value] = combo\n",
    "            all_combos.append(combo)\n",
    "            all_values.append(value)\n",
    "            value += 1\n",
    "\n",
    "    # apply new value to matching combos\n",
    "    k = 0\n",
    "    for value in all_values:\n",
    "        if value == 0:\n",
    "            combo = all_combos[k]\n",
    "            all_values[k] = [unique_combos[combo]][0]\n",
    "        k += 1\n",
    "\n",
    "    # create new array\n",
    "    new_array = np.array(all_values)\n",
    "    new_array = np.reshape(new_array, (-1, array1.shape[1]))\n",
    "\n",
    "    out = xr.DataArray(\n",
    "        data = new_array,\n",
    "        attrs = dict(\n",
    "            key = unique_values\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "combine_agg = combine_arrays(ndvi_2011, ndvi_2013, ndvi_2019)\n",
    "shade(combine_agg, cmap = Hot)"
   ]
  },
  {
   "source": [
    "Here the gradient represents each unique combination, the dotted areas of the same color represent combinations that were found lower in the image."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Equal to Frequency\n",
    "\n",
    "Let's find how many times the values of the rasters equal another."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_frequency(val_agg, agg_list):\n",
    "\n",
    "    out = []\n",
    "    in_aggs = [val_agg]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    # Iterate through each array simultaneously\n",
    "    for v, a, b, c in np.nditer(in_aggs):\n",
    "        count = 0\n",
    "        if np.isnan((a, b, c)).any() == True:   # skip nan\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        if v == a:\n",
    "            count += 1\n",
    "        if v == b:\n",
    "            count += 1\n",
    "        if v == c:\n",
    "            count += 1\n",
    "        out.append(count)\n",
    "\n",
    "    # create new array\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return out\n",
    "\n",
    "val_arr = np.zeros_like(ndvi_2011.data)\n",
    "val_agg = xr.DataArray(val_arr)\n",
    "agg_list = [ndvi_2011, ndvi_2011, ndvi_2019]\n",
    "ef = equal_frequency(val_agg, agg_list)\n",
    "shade(ef, cmap = Hot)"
   ]
  },
  {
   "source": [
    "Here we see the how many times a cell is equal to 0 among the three rasters. Black represents no occurances, yellow represents one occurance and white represents two. Note that in this example 'ndvi_2011' is listed twice. Because there are a limited number of cells where all values are the same, this is done to show change in frequency."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Greater than Frequency\n",
    "\n",
    "Let's find how many times the values of the rasters greater than another."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greater_frequency(val_agg, agg_list):\n",
    "\n",
    "    out = []\n",
    "    in_aggs = [val_agg]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    # Iterate through each array simultaneously\n",
    "    for v, a, b, c in np.nditer(in_aggs):\n",
    "        count = 0\n",
    "        if np.isnan((a, b, c)).any() == True:   # skip nan\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        if v < a:\n",
    "            count += 1\n",
    "        if v < b:\n",
    "            count += 1\n",
    "        if v < c:\n",
    "            count += 1\n",
    "        out.append(count)\n",
    "\n",
    "    # create new array\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return out\n",
    "\n",
    "val_arr = np.full_like(ndvi_2011.data, 0.5)\n",
    "val_agg = xr.DataArray(val_arr)\n",
    "agg_list = [ndvi_2011, ndvi_2013, ndvi_2019]\n",
    "gf = greater_frequency(val_agg, agg_list)\n",
    "shade(gf, cmap = Hot)"
   ]
  },
  {
   "source": [
    "Here we see the how many times a cell is greater than 0.5 among the three rasters. Black represents no occurances, orange represents one, yellow represents two and white represents three."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Highest Position\n",
    "\n",
    "Let's find the position of the raster with the maximum value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_array(agg_list):\n",
    "    i = -1\n",
    "    for a in agg_list:\n",
    "        highest = xr.ufuncs.maximum(agg_list[i], agg_list[i+1])\n",
    "        i+= 1\n",
    "\n",
    "    out = []\n",
    "    in_aggs = [highest]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    temp_vars = []\n",
    "    for number in range(0, len(agg_list)):\n",
    "        temp_vars.append(number)\n",
    "\n",
    "    for h, a, b, c in np.nditer(in_aggs):\n",
    "        if np.isnan((a, b, c)).any() == True:\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        if h == a:\n",
    "            out.append(1)\n",
    "        elif h == b:\n",
    "            out.append(2)\n",
    "        elif h == c:\n",
    "            out.append(3)\n",
    "\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return(out)\n",
    "\n",
    "agg_list = [ndvi_2011, ndvi_2013, ndvi_2019]\n",
    "ha = highest_array(agg_list)\n",
    "shade(ha, cmap = Hot)\n"
   ]
  },
  {
   "source": [
    "Here we see the position of the raster with the highest value. Black represents the position of first raster, in this case 'ndvi_2011' yellow is 1, white represents the position of 'ndvi_2013' or 2, and white represents the position of 'ndvi_2019' or 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Less than Frequency\n",
    "\n",
    "Let's find how many times the values of the rasters less than another."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lesser_frequency(val_agg, agg_list):\n",
    "\n",
    "    out = []\n",
    "    in_aggs = [val_agg]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    # Iterate through each array simultaneously\n",
    "    for v, a, b, c in np.nditer(in_aggs):\n",
    "        count = 0\n",
    "        if np.isnan((a, b, c)).any() == True:   # skip nan\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        if v > a:\n",
    "            count += 1\n",
    "        if v > b:\n",
    "            count += 1\n",
    "        if v > c:\n",
    "            count += 1\n",
    "        out.append(count)\n",
    "\n",
    "    # create new array\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return out\n",
    "\n",
    "val_arr = np.full_like(ndvi_2011.data, 0.5)\n",
    "val_agg = xr.DataArray(val_arr)\n",
    "agg_list = [ndvi_2011, ndvi_2013, ndvi_2019]\n",
    "lf = lesser_frequency(val_agg, agg_list)\n",
    "shade(lf, cmap = Hot)"
   ]
  },
  {
   "source": [
    "Here we see the how many times a cell is greater than 0.5 among the three rasters. Black represents no occurances, dark red represents one, red represents two and white represents three."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Lowest Position\n",
    "\n",
    "Let's find the position of the raster with the minimum value."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowest_array(agg_list):\n",
    "    for i in agg_list:\n",
    "        lowest = xr.ufuncs.minimum(i, i+1)\n",
    "\n",
    "    out = []\n",
    "    in_aggs = [lowest]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    for l, a, b, c in np.nditer(in_aggs):\n",
    "        if np.isnan((a, b, c)).any() == True:\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        if l == a:\n",
    "            out.append(1)\n",
    "        elif l == b:\n",
    "            out.append(2)\n",
    "        else:\n",
    "            out.append(3)\n",
    "\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return(out)\n",
    "\n",
    "agg_list = [ndvi_2011, ndvi_2013, ndvi_2019]\n",
    "la = lowest_array(agg_list)\n",
    "shade(ha, cmap = Hot)\n"
   ]
  },
  {
   "source": [
    "Here we see the position of the raster with the highest value. Black represents the position of first raster, in this case 'ndvi_2011' yellow is 1, white represents the position of 'ndvi_2013' or 2, and white represents the position of 'ndvi_2019' or 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Popularity\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def popularity(pop_agg, agg_list):\n",
    "\n",
    "    out = []\n",
    "    in_aggs = [pop_agg]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    for p, a, b, c in np.nditer(in_aggs):\n",
    "        if np.isnan((a, b, c)).any() == True:   # skip nan\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        inputs = np.array([a, b, c])\n",
    "\n",
    "        count_a = np.count_nonzero(inputs == a)\n",
    "        count_b = np.count_nonzero(inputs == b)\n",
    "        count_c = np.count_nonzero(inputs == c)\n",
    "        counts = np.array([count_a, count_b, count_c])\n",
    "\n",
    "        countsI = counts.argsort()\n",
    "        sorted_inputs = inputs[countsI][::-1]\n",
    "        sorted_counts = counts[countsI][::-1]\n",
    "\n",
    "        first = 0\n",
    "        second = 0\n",
    "        third = 0\n",
    "\n",
    "        if sorted_counts[0] == 1:\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "        elif sorted_counts[0] == 2:\n",
    "            first = sorted_inputs[0]\n",
    "            second = sorted_inputs[2]\n",
    "            third = np.nan\n",
    "        elif sorted_counts[0] == 3:\n",
    "            first = sorted_inputs[0]\n",
    "            second = sorted_inputs[1]\n",
    "            third = sorted_inputs[2]\n",
    "\n",
    "        if p == 1:\n",
    "            out.append(first)\n",
    "        elif p == 2:\n",
    "            out.append(second)\n",
    "        elif p == 3:\n",
    "            out.append(third)\n",
    "\n",
    "    # create new array\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return out\n",
    "\n",
    "val_arr = np.full_like(ndvi_2011.data, 2)\n",
    "val_agg = xr.DataArray(val_arr)\n",
    "agg_list = [ndvi_2011, ndvi_2013, ndvi_2019]\n",
    "p = popularity(val_agg, agg_list)\n",
    "shade(p, cmap = Hot)"
   ]
  },
  {
   "source": [
    "Here we see the position of the raster with the 2nd most popular value. Here black represents raster 1, orange raster , red raster three and white represents a cell where all values are the same level of popularity."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Rank"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(val_agg, agg_list):\n",
    "    out = []\n",
    "    in_aggs = [val_agg]\n",
    "    for agg in agg_list:\n",
    "        in_aggs.append(agg)\n",
    "\n",
    "    # Iterate through each array simultaneously\n",
    "    for v, a, b, c in np.nditer(in_aggs):\n",
    "        if np.isnan((a, b, c)).any() == True:   # skip nan\n",
    "            out.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        sort = np.sort((a, b, c))[::-1]\n",
    "        if v == 1:\n",
    "            out.append(sort[2])\n",
    "        elif v == 3:\n",
    "            out.append(sort[0])\n",
    "        else:\n",
    "            out.append(sort[1])\n",
    "    \n",
    "    # create new array\n",
    "    out = np.array(out)\n",
    "    out = np.reshape(out, (-1, agg_list[0].shape[1]))\n",
    "    out = xr.DataArray(out)\n",
    "    return out\n",
    "\n",
    "val_arr = np.full_like(ndvi_2011.data, 3)\n",
    "val_agg = xr.DataArray(val_arr)\n",
    "agg_list = [ndvi_2011, ndvi_2013, ndvi_2019]\n",
    "r = rank(val_agg, agg_list)\n",
    "shade(r, cmap = Hot)"
   ]
  },
  {
   "source": [
    "Here we see the 2nd ranked value of each cell. Here black represents raster 1, orange raster , red raster three and white represents a cell where al values are of equal rank (equal value)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}