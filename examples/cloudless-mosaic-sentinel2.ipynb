{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mosaic from a single multitemporal dataset\n",
    "\n",
    "\n",
    "The goal of this notebook is to provide an example of how to create a cloud-free mosaic from Sentinel-2 imagery over a specific area over a period of time. First, we use `satsearch` to search for Sentinel-2 data, then we combine the returned images using `stackstac`. Finally, a median operation is applied to merge the images into a single layer that can be saved as COGs in Azure blob storage for later use.\n",
    "\n",
    "\n",
    "## 1. Sentinel-2 Dataset\n",
    "\n",
    "Satellite images (also Earth observation imagery, spaceborne photography, or simply satellite photos) are images of Earth collected by imaging satellites typically operated by governments and businesses around the world (see https://en.wikipedia.org/wiki/Satellite_imagery). Major applications include Earth observation and land-cover monitoring. \n",
    "\n",
    "\n",
    "SENTINEL-2 (https://sentinel.esa.int/web/sentinel/user-guides/sentinel-2-msi/overview) is a wide-swath, high-resolution, multi-spectral imaging mission, supporting Copernicus Land Monitoring studies, including monitoring of vegetation, soil and water cover and observation of inland waterways and coastal areas.\n",
    "\n",
    "## 2. Environment setup\n",
    "\n",
    "The libraries we'll need are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import datashader as ds\n",
    "from datashader import Canvas\n",
    "\n",
    "import stackstac\n",
    "from satsearch import Search\n",
    "\n",
    "from azure.storage.blob import BlobClient\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "import xrspatial.multispectral as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "from dask_gateway import Gateway\n",
    "from distributed import Client\n",
    "from dask.distributed import PipInstall\n",
    "\n",
    "plugin = PipInstall(packages=[\"stackstac\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new cluster that is configured to use Dask-Gateway, and then a new client that executes all the Dask computations on that cluster. Finally, we can set the mode for the cluster to be adaptive so it resizes itself automatically based on the workload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = GatewayCluster()  # Creates the Dask Scheduler. Might take a minute.\n",
    "\n",
    "client = cluster.get_client()\n",
    "client.register_worker_plugin(plugin)\n",
    "\n",
    "cluster.adapt(minimum=8, maximum=100)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Sentinel 2 data\n",
    "\n",
    "In this example, we use image data from the `sentinel-s2-l2a-cogs` collection within a bounding box of `[-97.185642, 27.569157, -95.117574, 29.500710]`, and in the time range from `2019-07-01` to `2020-06-30`. And, we use only images with less than 25% cloud coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = Search(\n",
    "    url=\"https://earth-search.aws.element84.com/v0\",\n",
    "    bbox=[-96.185642, 28.569157, -95.117574, 29.500710],\n",
    "    collections=[\"sentinel-s2-l2a-cogs\"],\n",
    "    query={'eo:cloud_cover': {'lt': 25}},\n",
    "    datetime=\"2019-07-01/2020-06-30\"\n",
    ").items()\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine all the above STAC items into a lazy xarray with following settings:\n",
    "- projection: epsg=32613\n",
    "- resolution: 100m\n",
    "- bands: red (B04), green (B03), blue (B02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_ds = stackstac.stack(\n",
    "    items, epsg=32613, resolution=100, assets=['B04', 'B03', 'B02'], chunksize=4096\n",
    ")\n",
    "\n",
    "stack_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us all the image layers in one DataArray, but this is still quite a lot of images (216). We can simplify this a bit by resampling and combining the image layers for each month using a median calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly = stack_ds.resample(time=\"MS\").median(\"time\", keep_attrs=True)\n",
    "monthly.data = monthly.data.rechunk(1024, 1024)\n",
    "monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a much more manageable DataArray with 12 image layers (each with 3 bands) for 12 months."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cloud-free scene using median operator\n",
    "\n",
    "In this final stage, we use a median operation to merge all the monthly images into 1 single cloud-free layer. We use the assumption that, in a stack of images that are multitemporal, clouds wouldn't persist at the same geographical position from time to time. Hence, the more data we have, the better our chances of dropping the clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll combine the data, still in the xarray lazy mode, using the median operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_scene = monthly.median(dim=['time'])\n",
    "median_scene.data = median_scene.data.rechunk(2048, 2048)\n",
    "median_scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save median layer to Azure "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can send it up to Azure blob storage for easy retrieval and use in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "blob = BlobClient(\"https://xarrayspatial.blob.core.windows.net/\", \n",
    "                  \"examples-data\", \n",
    "                  \"median_layer.tiff\",\n",
    "                  credential='...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.upload_blob(median_scene)\n",
    "content_settings = ContentSettings(content_type='image/tiff')\n",
    "blob.set_http_headers(content_settings=content_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Downsample for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll generate an image of the cloud-free scene we just constructed using `xrspatial.multispectral`'s `true_color` function. \n",
    "\n",
    "We'll use the 3 bands we chose from the start - red, green, blue - and we'll first downsample and transform them into an image raster. Then, we'll apply true_color and get our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = 600, 800\n",
    "canvas = Canvas(plot_height=h, plot_width=w)\n",
    "resampled_agg = canvas.raster(median_scene)\n",
    "\n",
    "resampled_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`true_color` function takes 3 bands: red, green, blue as inputs and returns a PIL.Image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = ms.true_color(resampled_agg[2], resampled_agg[1], resampled_agg[0])\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to wrap things up nicely, we'll close the client and the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
